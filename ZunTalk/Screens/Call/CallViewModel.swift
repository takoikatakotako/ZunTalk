import SwiftUI
import Speech
import Accelerate

class CallViewModel: NSObject, ObservableObject {

    @Published var text = ""
    @Published var status: CallStatus = .idle

    private let recognizer = SFSpeechRecognizer(locale: Locale(identifier: "ja-JP"))
    private let engine = AVAudioEngine()
    private var request: SFSpeechAudioBufferRecognitionRequest?
    private var task: SFSpeechRecognitionTask?
    private var silenceTimer: Timer?
    
    private let silenceTime: TimeInterval = 2


    private var audioPlayer: AVAudioPlayer?
    private var playbackContinuation: CheckedContinuation<Bool, Never>?
    private var speechRecognitionStartTime: Date?

    // Repository
    private let voicevoxRepository: TextToSpeechRepository
    private let textGenerationRepository: TextGenerationRepository
    
    
    
    var chatMaggee: [ChatMessage] = []
    
    private let prompt = """
        „ÅÇ„Å™„Åü„ÅØ„Åö„Çì„Å†„ÅÆÂ¶ñÁ≤æ„ÅÆ„Åö„Çì„Å†„ÇÇ„Çì„Åß„Åô„ÄÇË™ûÂ∞æ„Å´„Äå„Å™„ÅÆ„Å†„Äç„Çí„Å§„Åë„ÄÅË¶™„Åó„Åø„ÇÑ„Åô„ÅèÊ•Ω„Åó„ÅÑÂè£Ë™ø„ÅßË©±„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
        ‰ªä„ÅØÈõªË©±„Åå„Åã„Åã„Å£„Å¶„Åç„Å¶Âèó„ÅëÂèñ„Å£„Åü„Å®„Åì„Çç„Åã„Çâ‰ºöË©±„ÇíÂßã„ÇÅ„Åæ„Åô„ÄÇ
        ÊúÄÂàù„ÅÆ„Çª„É™„Éï„ÅØÂøÖ„Åö„ÄåÈõªË©±„ÇíÂèó„Åë„ÅüÊÑü„ÅÆ„ÅÇ„ÇãÊå®Êã∂„Äç„Å´„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
        ‰æã: „Äå„ÇÇ„Åó„ÇÇ„Åó„ÄúÔºü„Åö„Çì„Å†„ÇÇ„Çì„Å™„ÅÆ„Å†ÔºÅ„Äç„ÄÅ„Äå„ÅØ„ÅÑ„ÅØ„Äú„ÅÑ„ÄÅ„Åö„Çì„Å†„ÇÇ„Çì„Å™„ÅÆ„Å†ÔºÅ„Äç„ÄÅ„Äå„ÅäÈõªË©±„ÅÇ„Çä„Åå„Å®„ÅÜ„Å™„ÅÆ„Å†ÔºÅ„Äç„Å™„Å©„ÄÇ
        ‰æã„ÇíÂèÇËÄÉ„Å´„Åó„Å§„Å§„ÄÅÊØéÂõûÂ∞ë„ÅóÈÅï„ÅÜË®Ä„ÅÑÂõû„Åó„Å´„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
        Êö¥ÂäõÁöÑ„ÉªÊîªÊíÉÁöÑ„Éª‰∏çÂø´„Å™Áô∫Ë®Ä„ÅØ„Åó„Å™„ÅÑ„Åß„Åè„Å†„Åï„ÅÑ„ÄÇ
        """
    
    init(voicevoxRepository: TextToSpeechRepository = VoicevoxRepository(), textGenerationRepository: TextGenerationRepository = OpenAITextGenerationRepository(apiKey: tempAPIKey)) {
        self.voicevoxRepository = voicevoxRepository
        self.textGenerationRepository = textGenerationRepository
    }

    func onAppear() {
        guard status == .idle else {
            print("idle‰ª•Â§ñ„Åã„ÇâÂëº„Å∞„Çå„Åæ„Åó„Åü")
            return
        }
        
        Task {
            do {
                try await main()
            } catch {
                print("Voicevox„Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó„Ç®„É©„Éº: \(error)")
            }
        }
    }
    
    private func main() async throws {
        // initializingVoiceVox
        status = .initializingVoiceVox
        try await initializingVoiceVox()
        
        // requestingPermission
        status = .requestingPermission
        let result = await requestSpeechRecognitionPermission()
        guard result else {
            // Ë®±ÂèØÂæó„Çâ„Çå„Å™„Åã„Å£„Åü
            print("Ë®±ÂèØÂæó„Çâ„Çå„Å™„Åã„Å£„Åü„Åß„Åô")
            return
        }
        
        // Play Incoming Call
        try playIncomingCall()
        
        // Generate Script
        status = .generatingScript
        assert(chatMaggee.isEmpty)
        chatMaggee.append(ChatMessage(role: .system, content: prompt))
        let script = try await generateScript(inputs: chatMaggee)

        // Generate Voice
        let voice = try await generateVoice(script: script)
        
        // Stop Incomint Call
        stopIncomingCall()
        
        // ‰ºöË©±ÊôÇÈñìÊ∏¨ÂÆöÈñãÂßã
        speechRecognitionStartTime = Date()

        // Play Voice
        try await playVoice(data: voice)

        // Start Speech Recognition
        try await startSpeachRecognition()
    }

    @MainActor
    private func initializingVoiceVox() async throws {
        // „Çπ„ÉÜ„Éº„Çø„ÇπÁ¢∫Ë™ç
        guard status == .initializingVoiceVox else {
            fatalError("initializingVoiceVox‰ª•Â§ñ„ÅÆ„Çπ„ÉÜ„Éº„Çø„Çπ„Åß„Åô")
        }
        
        // VOICEVOX„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´
        try await voicevoxRepository.installVoicevox()
        print("VoiceVox„ÅÆÂàùÊúüÂåñÂÆå‰∫Ü")
        
        // VOICEVOX„ÅÆ„Ç∑„É≥„Çª„Çµ„Ç§„Ç∂„Éº„ÅÆ„Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó
        try voicevoxRepository.setupSynthesizer()
        print("VOICEVOX„ÅÆ„Ç∑„É≥„Çª„Çµ„Ç§„Ç∂„ÉºÂàùÊúüÂåñÂÆå‰∫Ü")
    }
    
    @MainActor
    private func requestSpeechRecognitionPermission() async -> Bool {
        // „Çπ„ÉÜ„Éº„Çø„ÇπÁ¢∫Ë™ç
        guard status == .requestingPermission else {
            fatalError("requestingPermission‰ª•Â§ñ„ÅÆ„Çπ„ÉÜ„Éº„Çø„Çπ„Åß„Åô")
        }

        let authStatus = SFSpeechRecognizer.authorizationStatus()

        switch authStatus {
        case .authorized:
            return true
        case .denied, .restricted:
            return false
        case .notDetermined:
            break
        @unknown default:
            return false
        }

        // „É¶„Éº„Ç∂„Éº„Å´Ë®±ÂèØ„Çí„É™„ÇØ„Ç®„Çπ„Éà
        return await withCheckedContinuation { continuation in
            SFSpeechRecognizer.requestAuthorization { status in
                continuation.resume(returning: status == .authorized)
            }
        }
    }
    
    private func playIncomingCall() throws {
        // Èü≥Â£∞„ÅÆË™≠„ÅøËæº„Åø
        guard let asset = NSDataAsset(name: "maou_se_sound_phone02") else {
            // TODO: „Ç®„É©„Éº„Éè„É≥„Éâ„É™„É≥„Ç∞
            fatalError("Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì")
        }

        // ÁùÄ‰ø°Èü≥ÂÜçÁîü
        audioPlayer = try AVAudioPlayer(data: asset.data)
        audioPlayer?.numberOfLoops = -1
        audioPlayer?.prepareToPlay()
        audioPlayer?.play()
    }
    
    @MainActor
    private func generateScript(inputs: [ChatMessage]) async throws -> String {
        // „Çπ„ÉÜ„Éº„Çø„ÇπÁ¢∫Ë™ç
        guard status == .generatingScript else {
            fatalError("generatingScript‰ª•Â§ñ„ÅÆ„Çπ„ÉÜ„Éº„Çø„Çπ„Åß„Åô")
        }

        let script = try await textGenerationRepository.generateResponse(inputs: inputs)
        print(script)
        return script
    }

    @MainActor
    private func generateVoice(script: String) async throws -> Data {
        print("Èü≥Â£∞ÂêàÊàê")
        status = .synthesizingVoice

        let data = try await voicevoxRepository.synthesize(text: script)
        return data
    }
    
    private func stopIncomingCall() {
        audioPlayer?.stop()
    }
    
    @MainActor
    private func playVoice(data: Data) async throws {
        status = .playingVoice

        audioPlayer = try AVAudioPlayer(data: data)
        audioPlayer?.delegate = self
        audioPlayer?.prepareToPlay()
        audioPlayer?.play()

        // ÂÜçÁîüÁµÇ‰∫Ü„ÇíÂæÖ„Å§
        let success = await withCheckedContinuation { continuation in
            playbackContinuation = continuation
        }

        if !success {
            print("Èü≥Â£∞ÂÜçÁîü„Å´Â§±Êïó„Åó„Åæ„Åó„Åü")
        }
    }
    
    // Èü≥Â£∞Ë™çË≠òÈñãÂßã
    @MainActor
    private func startSpeachRecognition() async throws {
        print("üé§ Èü≥Â£∞Ë™çË≠òÈñãÂßã")

        status = .recognizingSpeech
        text = ""

        // Èü≥Â£∞„Çª„ÉÉ„Ç∑„Éß„É≥„ÅÆË®≠ÂÆö
        let audioSession = AVAudioSession.sharedInstance()
        try audioSession.setCategory(.playAndRecord, mode: .voiceChat, options: [.defaultToSpeaker, .mixWithOthers])
        try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
        print("‚úÖ Èü≥Â£∞„Çª„ÉÉ„Ç∑„Éß„É≥Ë®≠ÂÆöÂÆå‰∫Ü")

        // Èü≥Â£∞Ë™çË≠ò„É™„ÇØ„Ç®„Çπ„Éà„ÅÆ‰ΩúÊàê
        request = SFSpeechAudioBufferRecognitionRequest()
        request?.shouldReportPartialResults = true
        print("‚úÖ Èü≥Â£∞Ë™çË≠ò„É™„ÇØ„Ç®„Çπ„Éà‰ΩúÊàêÂÆå‰∫Ü")

        let input = engine.inputNode
        let format = input.outputFormat(forBus: 0)

        print("üìä Èü≥Â£∞„Éï„Ç©„Éº„Éû„ÉÉ„Éà - „Çµ„É≥„Éó„É´„É¨„Éº„Éà: \(format.sampleRate)Hz, „ÉÅ„É£„Éç„É´Êï∞: \(format.channelCount)")

        input.removeTap(onBus: 0)
        input.installTap(onBus: 0, bufferSize: 1024, format: format) { buf, _ in
            self.request?.append(buf)
        }
        print("‚úÖ Èü≥Â£∞„Çø„ÉÉ„ÉóË®≠ÂÆöÂÆå‰∫Ü")

        // Èü≥Â£∞Ë™çË≠ò„Çø„Çπ„ÇØ„ÅÆÈñãÂßã
        task = recognizer?.recognitionTask(with: request!) { result, error in
            if let error = error {
                print("‚ùå Èü≥Â£∞Ë™çË≠ò„Ç®„É©„Éº: \(error.localizedDescription)")
                return
            }

            guard let result = result else { return }

            let recognizedText = result.bestTranscription.formattedString
            print("üó£Ô∏è Ë™çË≠òÁµêÊûú: \(recognizedText)")
            print("üìù Ë™çË≠òÁä∂ÊÖã: \(result.isFinal ? "ÊúÄÁµÇ" : "ÈÄî‰∏≠")")

            if result.isFinal {
                print("‚úÖ Èü≥Â£∞Ë™çË≠òÂÆå‰∫Ü")
                return
            }

            DispatchQueue.main.async {
                self.text = recognizedText
                print("XXX: \(self.text)")
            }

            print("üîá ÁÑ°Èü≥Ê§úÂá∫ - „Çø„Ç§„Éû„ÉºÈñãÂßãÔºà\(self.silenceTime)ÁßíÂæå„Å´Âá¶ÁêÜÂÆüË°åÔºâ")
            self.silenceTimer?.invalidate()
            self.silenceTimer = Timer.scheduledTimer(withTimeInterval: self.silenceTime, repeats: false) { _ in
                print("‚è∞ 2Áßí‰ª•‰∏ä„ÅÆÁÑ°Èü≥„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü - Èü≥Â£∞Ë™çË≠ò„ÇíÂÅúÊ≠¢„Åó„Åæ„Åô")
                Task {
                    try? await self.stop()
                }
            }
        }
        print("‚úÖ Èü≥Â£∞Ë™çË≠ò„Çø„Çπ„ÇØÈñãÂßã")

        // Èü≥Â£∞„Ç®„É≥„Ç∏„É≥„ÅÆÈñãÂßã
        try engine.start()
        print("‚úÖ Èü≥Â£∞„Ç®„É≥„Ç∏„É≥ÈñãÂßãÊàêÂäü")
    }

    @MainActor
    func stop() async throws {
        print("‚èπÔ∏è Èü≥Â£∞Ë™çË≠òÂÅúÊ≠¢")

        engine.stop()
        engine.inputNode.removeTap(onBus: 0)
        request?.endAudio()
        task?.finish()

        print("‚úÖ Èü≥Â£∞Ë™çË≠òÂÅúÊ≠¢ÂÆå‰∫Ü")

        // ‰ºöË©±ÊôÇÈñì„ÇíÁ¢∫Ë™ç
        if let startTime = speechRecognitionStartTime {
            let elapsedTime = Date().timeIntervalSince(startTime)
            if elapsedTime >= 60 {
                print("‚è±Ô∏è ‰ºöË©±ÊôÇÈñì„Åå1ÂàÜ‰ª•‰∏ä„Åß„Åô: \(Int(elapsedTime))Áßí")
            }
        }

        status = .processingResponse
        chatMaggee.append(ChatMessage(role: .user, content: text))

        status = .generatingScript
        let script = try await generateScript(inputs: chatMaggee)

        let voice = try await generateVoice(script: script)

        chatMaggee.append(ChatMessage(role: .assistant, content: script))
        text = script

        try await playVoice(data: voice)

        // Start Speech Recognition
        try await startSpeachRecognition()
    }
}

// MARK: - AVAudioPlayerDelegate
extension CallViewModel: AVAudioPlayerDelegate {
    func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
        playbackContinuation?.resume(returning: flag)
        playbackContinuation = nil
    }

    func audioPlayerDecodeErrorDidOccur(_ player: AVAudioPlayer, error: Error?) {
        print("Èü≥Â£∞„Éá„Ç≥„Éº„Éâ„Ç®„É©„Éº: \(error?.localizedDescription ?? "‰∏çÊòé„Å™„Ç®„É©„Éº")")
        playbackContinuation?.resume(returning: false)
        playbackContinuation = nil
    }
}

